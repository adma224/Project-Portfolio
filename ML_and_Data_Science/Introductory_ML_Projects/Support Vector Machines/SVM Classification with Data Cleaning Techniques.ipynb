{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing SVM Classification with Data Cleaning Techniques\n",
    "\n",
    "In this project, we explore the impact of data cleaning techniques on the performance of SVM classifiers. By artificially introducing label noise into a synthetic dataset and then applying various data cleaning methods (KNN, K-Means, GMM), we aim to investigate how these preprocessing steps affect SVM classification accuracy. This study provides insights into the robustness of SVM and the effectiveness of different data cleaning strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "test_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation and Initial Setup\n",
    "\n",
    "We start by generating synthetic data points with Gaussian distributions and introduce label noise. This setup simulates a real-world scenario where data labels might be noisy or inaccurate. Our objective is to clean this data and improve the classification accuracy of an SVM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_p = np.random.normal(1,1,size=(1000+test_size,2))\n",
    "co_n = np.random.normal(1,1,size=(1000+test_size,2))\n",
    "\n",
    "X_p = pd.DataFrame(co_p,columns=['x0','x1'])\n",
    "X_n = pd.DataFrame(co_n,columns=['x0','x1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Before applying any cleaning techniques, we explore the synthetic dataset. Visualizations of the data points and their respective labels give us an initial understanding of the noise level and data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310211</td>\n",
       "      <td>0.062671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.341702</td>\n",
       "      <td>1.586315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033272</td>\n",
       "      <td>1.867829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1\n",
       "0  0.310211  0.062671\n",
       "1  1.341702  1.586315\n",
       "2  0.033272  1.867829"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.292501</td>\n",
       "      <td>0.904944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.551903</td>\n",
       "      <td>1.655517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.212995</td>\n",
       "      <td>1.573792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1\n",
       "0  1.292501  0.904944\n",
       "1  1.551903  1.655517\n",
       "2  1.212995  1.573792"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classification with Noisy Labels\n",
    "\n",
    "Initially, we train an SVM classifier on the noisy dataset to establish a baseline for classification accuracy. This step will allow us to quantify the improvement brought by subsequent data cleaning methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.35270\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "for i in range(0,20):\n",
    "    \n",
    "    # Flipping Labels\n",
    "    y_p = np.full(1000+test_size,1)\n",
    "    y_n = np.full(1000+test_size,-1)\n",
    "    for j in range(0,len(y_p)):\n",
    "        y_p[j] = 1 if (random.randint(0,100)>35) else -1\n",
    "    for j in range(0,len(y_n)):\n",
    "        y_n[j] = -1 if (random.randint(0,100)>20) else 1\n",
    "        \n",
    "    # Constructing Dataframe\n",
    "    df_p = pd.concat([X_p, pd.DataFrame(y_p, columns=['y'])], axis=1)\n",
    "\n",
    "\n",
    "    df_n = pd.concat([X_n, pd.DataFrame(y_n, columns=['y'])], axis=1)\n",
    "\n",
    "    df = pd.concat([df_p, df_n], axis=0)\n",
    "\n",
    "    \n",
    "    # Running SVM\n",
    "    clf_a = svm.SVC(kernel='rbf', C=1, gamma=0.01)\n",
    "    clf_a.fit(df[['x0','x1']][:1000],df['y'][:1000])\n",
    "    score = clf_a.score(df[['x0','x1']][1000:],df['y'][1000:])\n",
    "    \n",
    "    # Report Scores\n",
    "    mean +=score\n",
    "    \n",
    "mean = mean/20\n",
    "print(\"Mean: {:.5f}\".format(mean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning with KNN\n",
    "\n",
    "We apply the K-Nearest Neighbors algorithm to clean the data. The idea is to see if using the labels of nearest neighbors can reduce label noise and improve SVM performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     y_n[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Constructing Dataframe\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_p \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_p,pd\u001b[38;5;241m.\u001b[39mDataFrame(y_p,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m df_n \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_n,pd\u001b[38;5;241m.\u001b[39mDataFrame(y_n,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m df  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_p,df_n],\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: concat() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "for i in range(0,20):\n",
    "    \n",
    "    # Flipping Labels\n",
    "    y_p = np.full(1000+test_size,1)\n",
    "    y_n = np.full(1000+test_size,-1)\n",
    "    for j in range(0,len(y_p)):\n",
    "        y_p[j] = 1 if (random.randint(0,100)>35) else -1\n",
    "    for j in range(0,len(y_n)):\n",
    "        y_n[j] = -1 if (random.randint(0,100)>20) else 1\n",
    "        \n",
    "    # Constructing Dataframe\n",
    "    df_p = pd.concat([X_p,pd.DataFrame(y_p,columns=['y'])],1)\n",
    "    df_n = pd.concat([X_n,pd.DataFrame(y_n,columns=['y'])],1)\n",
    "    df  = pd.concat([df_p,df_n],0)\n",
    "    \n",
    "    cleaner = KNeighborsClassifier(n_neighbors=100).fit(df[['x0','x1']],df['y'])\n",
    "    df['y'] = cleaner.predict(df[['x0','x1']])\n",
    "    \n",
    "    # Running SVM\n",
    "    clf_a = svm.SVC(kernel='rbf', C=1, gamma=0.01)\n",
    "    clf_a.fit(df[['x0','x1']][:1000],df['y'][:1000])\n",
    "    score = clf_a.score(df[['x0','x1']][1000:],df['y'][1000:])\n",
    "    \n",
    "    # Report Scores\n",
    "    print(score)\n",
    "    mean +=score\n",
    "    \n",
    "mean = mean/20\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     y_n[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Constructing Dataframe\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_p \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_p,pd\u001b[38;5;241m.\u001b[39mDataFrame(y_p,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m df_n \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_n,pd\u001b[38;5;241m.\u001b[39mDataFrame(y_n,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m df  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_p,df_n],\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: concat() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "for i in range(0,20):\n",
    "    \n",
    "    # Flipping Labels\n",
    "    y_p = np.full(1000+test_size,1)\n",
    "    y_n = np.full(1000+test_size,-1)\n",
    "    for j in range(0,len(y_p)):\n",
    "        y_p[j] = 1 if (random.randint(0,100)>35) else -1\n",
    "    for j in range(0,len(y_n)):\n",
    "        y_n[j] = -1 if (random.randint(0,100)>20) else 1\n",
    "        \n",
    "    # Constructing Dataframe\n",
    "    df_p = pd.concat([X_p,pd.DataFrame(y_p,columns=['y'])],1)\n",
    "    df_n = pd.concat([X_n,pd.DataFrame(y_n,columns=['y'])],1)\n",
    "    df  = pd.concat([df_p,df_n],0)\n",
    "    \n",
    "    df['y'] = KMeans(n_clusters=2, random_state=0).fit_predict(df[['x0','x1']])\n",
    "    \n",
    "    # Running SVM\n",
    "    clf_a = svm.SVC(kernel='rbf', C=1, gamma=0.01)\n",
    "    clf_a.fit(df[['x0','x1']][:1000],df['y'][:1000])\n",
    "    score = clf_a.score(df[['x0','x1']][1000:],df['y'][1000:])\n",
    "    \n",
    "    # Report Scores\n",
    "    print(score)\n",
    "    mean +=score\n",
    "    \n",
    "mean = mean/20\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     y_n[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Constructing Dataframe\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_p \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_p,pd\u001b[38;5;241m.\u001b[39mDataFrame(y_p,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m df_n \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_n,pd\u001b[38;5;241m.\u001b[39mDataFrame(y_n,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m df  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_p,df_n],\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: concat() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "for i in range(0,20):\n",
    "    \n",
    "    # Flipping Labels\n",
    "    y_p = np.full(1000+test_size,1)\n",
    "    y_n = np.full(1000+test_size,-1)\n",
    "    for j in range(0,len(y_p)):\n",
    "        y_p[j] = 1 if (random.randint(0,100)>35) else -1\n",
    "    for j in range(0,len(y_n)):\n",
    "        y_n[j] = -1 if (random.randint(0,100)>20) else 1\n",
    "        \n",
    "    # Constructing Dataframe\n",
    "    df_p = pd.concat([X_p,pd.DataFrame(y_p,columns=['y'])],1)\n",
    "    df_n = pd.concat([X_n,pd.DataFrame(y_n,columns=['y'])],1)\n",
    "    df  = pd.concat([df_p,df_n],0)\n",
    "    \n",
    "    df['y'] = GaussianMixture(n_components=2, covariance_type='full').fit_predict(df[['x0','x1']])\n",
    "    \n",
    "    # Running SVM\n",
    "    clf_a = svm.SVC(kernel='rbf', C=1, gamma=0.01)\n",
    "    clf_a.fit(df[['x0','x1']][:1000],df['y'][:1000])\n",
    "    score = clf_a.score(df[['x0','x1']][1000:],df['y'][1000:])\n",
    "    \n",
    "    # Report Scores\n",
    "    print(score)\n",
    "    mean +=score\n",
    "    \n",
    "mean = mean/20\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
